# MetaMarkup: Technical Notes


The MetaMarkup library provides a parser and renderer which is capable of transforming text in multiple markup languages into HTML in real time.  The text is rendered as you type, and syntax errors are noted in the rendered text as they occur.  The languages implemented in the present system are

- L1: a markup language with a syntax inspired by Lisp.

- Rational Markdown:  a variant  of Markdown which can render mathematical formulas, provide numbered section headings, a table of contents, etc.

-  MiniLaTeX, a subset of LaTeX with a few added features.

The task of managing multiple languages is made possible by a rules-based shift-reduce parser that transforms source code from any of the target languages to a common AST.  To change markup languages, one changes the rule set.  A single rendering function suffices to render the comon AST to HTML.


## Parsing

The  parser consumes the source text as a list of strings, transforming it first into a list of blocks. Blocks are entities such as paragraphs, quotations, and LaTeX environments.
Once the blocks have been found, their contents are parsed to handle inline constructs such as TeX macros, marked text such as the below, and so on.

```
   *bold*, _italic_, `a[i] = a[i] + 1`, $a^2 + b^2 = c^2$,
   \section{Introduction}, \emph{important stuff]

The flow of data is

```
   List String -> List Block -> List TextBlock -> List (Html msg)

where the source text has type `List String` and the ulltimate AST, common to all languages handled, is of type `List TextBlock`.

### Block parser

The first step is carried out by a function

```
   Block.parse: Language -> Int -> List String -> List Block

where

```
   type Language
        = L1
        | Markdown
        | MiniLaTeX

The sole dependency on the `Language` argument is via the function

```
   classify : Language -> Bool -> String -> LineTypeData

This function examines a string, principally to determine line type:

```
    type LineType
        = OrdinaryLine
        | VerbatimLine
        | BlankLine
        | BeginBlock String
        | EndBlock String
        | BeginVerbatimBlock String
        | EndVerbatimBlock String
        | Problem String

The language dependency is in fact concentrated in the function

```
   getLineTypeParser : Language -> String -> LineType

where, for instance, the function `getLine Markdown` has type `String -> LineType.` Functions of this type, one for each language, are what do the actual work.  Their implementation is quite small, about 50 lines of code.


### Text parser

The second step, parsing from `Blocks` to `TextBlocks` is carried  out by mapping a function
`parseText : Language -> String -> List Text` over the list of blocks:

```
    parse2 : Language -> List Block -> List TextBlock
    parse2 language blocks =
        List.map (Syntax.map (parseText language)) blocks

The core of the `parserText` function is a call to `Cursor.parserLoop,` a shift-reduce parser whose operation is defined by a set of language-specific rules which are loaded as the first argument.  Here `parserLoop` is a functional loop operating on a `TextCursor,` a structure with fields

- `sourceText: String` — the input

- `scanPoint` — an index into `sourceText`

- `stack: List Text` — data not completely parsed

- `committed: List Text` — the output


#### Rules

A rule is a record with various fields including

- two predicates which define a parser that accepts a string, e.g., `"\foo"` from the input
`"\foo{bar}"` for the beginning of a LaTeX macro.

- a list of "expectations," e.g.,

```
     [  { stop = [ " ", "" ], action = CommitMarked }
      , { stop = [ "{" ], action = ShiftMarked } ]

 On each pass of `parserLoop,` the `textToProcess` is  set to the source text from `scanPoint`  on and he current rule is computed from by the rule set and the leading character of `textToProcess.`  The current rule determines a parser which returns a prefix of `textToProcess,` advances the `scanPoint,` and finds `stopChar,` the character in the source text just beyond `scanPoint.`  This character and the current rule determine an action, as in the rule example above.  A case statement based on the action then determines how to update the `committed` and `stack` fields of the text cursor.

If the action is `ShiftMarked,` the `committed` field is left untouched and the `Text` element `Marked str meta` is prepended to the `stack` field.  Here `str` is a substring of the prefix and `meta` locates that prefix in the source.


#### Actions

Every rule has an `Action` field, and every `Action` variant appears in the `case currentParser textToProcess` clause of `Cursor.nextCursor,` where it defines how the `committed` and `stack` fields of the text cursor are to be updated.  There are seven variant actions, as listed below.  Most are generic, but two  — `ShiftVerbatim2` and `ReduceArgList` — are there to process L1 source text.

```
   type Action
        = Commit
        | CommitMarked
        | ShiftText
        | ShiftText2
        | ShiftMarked
        | ShiftVerbatim String
        | ShiftVerbatim2 String
        | ShiftArg
        | ReduceArg
        | ReduceArgList
        | ErrorAction

Notice that there are there types of actions: shift, reduce, and handle error.

##### Examples

1. If the action is `ShiftText,` then `nextCursor` ans already parserd a string from the sooutce text.  If the stack is empty, then the string is prepended as `Text str` to `committed.` If the stack is not empty, it is prepended as `Text str` to the stack.

2. If the action is `CommitMarked,` the data `Marked str meta` is prepended to the `committed` field instead and `stack` is left untouched.

3. If the action is `ReduceArg,` then the commited text is left untouched and the function `contractTextIntoArg >> contractArgIntoMarked >> contractMarkedIntoArg` is applied to the stack.  Each function in a chain like this has signature `List Text -> List Text,` and it acts via pattern-matching on the first two or three elements on the stack to replace these elements by a single combined element.  For example, we have

```
    contractTextIntoArg stack =
        case stack of
            (Text str meta1) :: (Arg textList2 meta2) :: rest ->
                Arg (Text str meta1 :: textList2) META :: rest
            _ ->
                stack

where `META` is new metadata.  If the stack reads

```
   Text "foo" ... :: Arg [ ] ... :: rest

before contraction, then afterwards it will read

```
   Arg [Text "foo" ...] ... :: rest




## Language Dependencies

It takes two files and about 150 lines of code to define a markup language that can be handled by MetaMarkup.  We make no claim about the scope of the system.  It is adequate for L1, Rational Markdown, and MiniLaTeX, despite their obvous surface differences.  It would be interesting to characterize the kind of languages that can be handled by this system or close relaitves thereof.


## Rendering

The final step, rendering a list of `TextBlock` to a list of type `Html msg,` is carried out by a single language-independent function,

```
   render : Int -> Settings -> List TextBlock -> List (Element msg)

The AST, of type `List TextBlock,` is expressive enough to handle markup languages as different as L1, Markdown and MiniLaTeX.  For L1  we have

```
   [b important] => Marked "b" (Text Impotant)

while in Markdown the same construct reads

```
   *important* => Marked "*" (Text "important")

with MiniLaTeX as in this last example:

```
   \strong{important}  => Marked "strong" (Text "important")

The renderer has a dictionary that maps names of  `Marked` elements to rendering functions.  In the case at hand, the names `b,` `*` and `strong` are mapped to the same element.

## Export to LaTeX and PDF

One advantage of our design describe is that printing to PDF of any of languages discussed can be implemented by a single which emits standard LaTeX source code:

```
   renderToLaTeX : List TextBlock -> String

With this function as the final step in the pipeline considered above, we transform markup source text to LaTeX source text.  This can then be shipped to a server that accepts LaTeX files and returns them transformed into PDF.  We are currently using a server implemented in under 200 lines of Haskell code.



